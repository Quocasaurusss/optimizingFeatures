# optimizingFeatures
This project came about after I learned some machine learning basics. I was motivated by the desire to minimize the mean absolute error
generated by my machine learning model using the knowledge that I already had. I thought that a cool way to go about it was by optimizing
the features that I chose to train my model. With 34 total features (that were numeric data types) in the dataset and an obnoxious number 
of combinations in which features can be chosen (although within the code I only opted to look for 5-feature combinations), the chances that I would choose the perfect one were slim, so I decided to let my code do it instead. This project was not a complete success because I was never able to form a perfect algorithm that would search only n choose k search space, but this project tied together some of the things that I had learned in my college courses with new ML skills that I had acquired, resulting in a balance between theory and application that I found very enjoyable regardless of the results.
